```bash
LINK: https://blog.streamlit.io/how-to-build-a-llama-2-chatbot/
```
```bash
DOCKERIMAGE: dockerhub.zeblok.io/zeblok/streamlit:v1698301125
PORT: HTTP(8501)
```
```bash
While spawning streamlitui microservice pass this environment variable
ZBLC_LLM_ENDPOINT: http://<service-ip-of-llm-microservice>:2600/v1/completions
```
```bash
ANOTHER LINKS
How to build a Llama 2 chatbot - https://blog.streamlit.io/how-to-build-a-llama-2-chatbot/
How to Build a UI for your Model using Streamlit - https://www.section.io/engineering-education/streamlit-ui-tutorial/
Deploy Streamlit using Docker - https://docs.streamlit.io/knowledge-base/tutorials/deploy/docker
Streamlit example - https://github.com/streamlit/streamlit-example/blob/master/streamlit_app.py
Prompt templates - https://llm.datasette.io/en/stable/templates.html
LLM quickstart - https://docs.streamlit.io/knowledge-base/tutorials/llm-quickstart
Fine-tuning with Retrieval Augmentation - https://docs.llamaindex.ai/en/stable/examples/finetuning/knowledge/finetune_retrieval_aug.html
```
